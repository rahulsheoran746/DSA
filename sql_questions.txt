1.	Given a table that includes user_id, session_id, start_time, and end_time, write a query to find each user's average and maximum time spent.

select user_id, 
max(datediff('second', start_time ,end_time)) as max_time_diff
avg(datediff('second', start_time ,end_time)) as avg_time_diff
from table group by user_id

2.	Given the table Employees (columns: EmployeeID, Name, Department, Salary), write a query to rank employees within each department by their salary in descending order.

select employee_id, name, department, salary, 
rank() over(partition by department order by salary desc) as rnk
from employees

3.	Given the table StockPrices (columns: StockID, PriceDate, Price), calculate the 3-day moving average of stock prices.

select stockid, pricedate, price,
avg(price) over(partition by stockid 
		order by pricedate 
		rows between 2 preceding and current row
		) as avg_price
from stockprices


4.	You have two tables: 
o	employees(emp_id, emp_name, department_id, salary, hire_date)
o	departments(department_id, department_name) 
Write a query to calculate the difference between each employee’s salary and the highest salary within their department. Then, label employees who have a salary within 1000 of the department's highest salary as 'Near Top Earner'.


select emp_id, emp_name, dept_id, salary, hire_date,
(max(salary) over(partition by department_id) - salary)as salary_diff,
case 
when (max(salary) over(partition by department_id) - salary) <=1000  then 'near_top_earner',
else null
end as label
from employees

with salary_info as (
select emp_id, emp_name, dept_id, salary,
max(salary) over(partition by dept_id) as max_salary
from employees
)

select *, 
(max_salary - salary) as salary_diff,
case
when (max_salary - salary) <=1000 then 'near_top_earner'
else null
end as label
from salary info 


5.	Given the userProfile table with fields: 
o	userId
o	ctc
o	total_exper
And the communicationSend table with fields: 
o	userId
o	date
o	communicationType
Write a SQL query to find the distribution of users who have an entry in the communicationSend table with "notification" communication type in the last 30 days. Group users into buckets: 
o	Send count bucket: 0-5, 5-10, 10-15, >15
o	CTC bucket: 0-5, 5-10, 10-15, >15
o	Experience bucket: 0-5, 5-10, 10-15, >15


with user_send_count as (
select u.user_id,
u.ctc,
u.toal_exper
count(u.userid) as send_count
from userprofile u 
left join 
communicationsend c 
on u.userid = c.userid
where communicationType = 'notification' and datediff('day', c.date, currentdate)<=30
group by u.user_id, u.ctc, u.total_exper
),
buckets as (
select user_id,

CASE 
      WHEN send_count BETWEEN 0 AND 4 THEN '0-5'
      WHEN send_count BETWEEN 5 AND 9 THEN '5-10'
      WHEN send_count BETWEEN 10 AND 14 THEN '10-15'
      ELSE '>15'
    END AS send_count_bucket,

    -- CTC bucket
    CASE 
      WHEN ctc BETWEEN 0 AND 4 THEN '0-5'
      WHEN ctc BETWEEN 5 AND 9 THEN '5-10'
      WHEN ctc BETWEEN 10 AND 14 THEN '10-15'
      ELSE '>15'
    END AS ctc_bucket,

    -- Experience bucket
    CASE 
      WHEN total_exper BETWEEN 0 AND 4 THEN '0-5'
      WHEN total_exper BETWEEN 5 AND 9 THEN '5-10'
      WHEN total_exper BETWEEN 10 AND 14 THEN '10-15'
      ELSE '>15'
    END AS experience_bucket
from user_send_count
)

select send_count_bucket, 
ctc_bucket,
experience_bucket,
 count(*) as user_count
 from buckets 
group by   send_count_bucket,
  ctc_bucket,
  experience_bucket
order by 
send_count_bucket,
  ctc_bucket,
  experience_bucket;


I have a table sales_id, product_name, sales_date. We have to give only those rows with latest data based on sales_date.

with ranked_sales as (
select sales_id, product_name ,sales_date,
row_number() over(partition by product_name order by sales_date) as rn
from sales)

select * from ranked_sales where rn =1


A company maintains information about its order on orders table. Write a query to print details of the earliest five orders(sorted by order_date ascending) that have not been delivered(i.e status is not delivered). If there are more than 5 orders to chose from select the ones with the lowest order id. Sort the output in the increasing order of the order_id. the output should contains id, order_date, status, customer_id.

select order_id, order_date,status, customer_id from (
select order_id, order_date,status, customer_id from orders where status !='delivered' order by order_date, order_id limit 5) as sub order by order_id.



Q1. Given a table users in which we have columns as user_id, deptartment, salary and we have to find the diff between 2nd and 3rd highest salary of each dept.



with ranked_salaries as (
	select 
	department, salary,
	dense_rank() over(partition by department order by salar desc) as rnk
	from users
),
filtered as (
	select department, salary,rnk
	from ranked_salaries where rnk in (2, 3)
)

select department,
max(case when rnk = 2 then salary end) as second_highest,
max(case when rnk = 3 then salary end) as third_highest,
max(case when rnk = 2 then salary end)  -  max(case when rnk = 3 then salary end ) as salary_diff
from filtered
group by department
having count(distinct rnk) = 2; 


Q2 You are given a table user_sales with the following columns:

user_id (unique identifier for each user),

quarter (values: 'Q1', 'Q2', 'Q3', 'Q4'),

sales (sales amount for that user in the respective quarter).

Write a SQL query to pivot this data such that each row represents a user and their sales in each quarter, with the output columns:

user_id, Q1_sales, Q2_sales, Q3_sales, Q4_sales.


select user_id,
max(case when quarter = 'Q1' then sales end) as Q1_sales,
max(case when quarter = 'Q2' then sales end) as Q2_sales,
max(case when quarter = 'Q3' then sales end) as Q3_sales,
max(case when quarter = 'Q4' then sales end) as Q4_sales
from sales group by user_id;


You are given three tables:

users(user_id, user_name, manager_id) — contains information about employees and their respective managers.

managers(manager_id, manager_name) — contains information about managers.

orders(order_id, user_id, order_date) — contains information about orders placed by users.

Task:
Write a SQL query to find the names of employees (user_name) and their corresponding manager_name for all employees who have not placed any orders.

select 
u.user_name,
m.manager_name
from users u
left join 
order o on o.user_id = u.user_id
left join managers m on m.manager_id = u.manager_id
where o.user_id is null;


You are given two tables:

employee(emp_id, emp_name, emp_salary, dep_name) 
department(dept_id, dept_name)
Find the emp_name and the corresponding dept_id of employees whose emp_salary is greater than the average salary of their department.

with avg_salary_dept as(
select dep_name, avg(emp_salary) as avg_salary from employee group by dep_name
)

select e.emp_name, d.dept_id
from  employee e 
join 
avg_salary_dept a on e.dept_name = a.dep_name
join 
department d on d.dept_name = e.dept_name
where e.emp_salary > a.avg_salary;



You are given a DataFrame with the following columns:
user_id (integer): Unique identifier for each student
name (string): Name of the student
marks (array of integers): A list containing the marks obtained by the student in 5 different subjects

You are required to calculate the average of the top 3 marks for each student.

from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, col, row_number, avg, round
from pyspark.sql.window import Window


spark = SparkSession.builder\
        .appName('Top 3 average marks ')\
        .getOrCreate()

print('Spark session started successfully.')
spark.sparkContext.setLogLevel('FATAL')

student_date = [(1, 'Janit', [80,70,81,54,90]),
                (2, 'Ankit', [81,72,81,54,91]),
                (3, 'Syed', [82,74,81,56,92]),
                (4, 'Lokesh', [83,76,81,58,93]),
                (5, 'Nishant', [84,70,81,60,94])]

df = spark.createDataFrame(student_date, ['user_id','user_name','marks'])
df.printSchema()

# df.show(truncate = False)

exploded_df = df.withColumn('exploded_marks', explode(col('marks'))).drop(col('marks'))
# exploded_df.show(truncate = False)

window_spec = Window.partitionBy(col('user_id')).orderBy(col('exploded_marks').desc())

r_df = exploded_df.withColumn('row_no', row_number().over(window_spec)).filter(col('row_no').isin([1,2,3]))

# r_df.show(truncate = False)

final_df = r_df.groupby('user_id','user_name').agg(
    round(avg(col('exploded_marks')), 2).alias('avg_marks'))
final_df.show(truncate = False)

"Given a table named users with the following columns: user_id, product_id, and sales, write an SQL query to fetch the top two sales (highest sales amounts) for each user."

select user_id, product_id , sales, 
row_number() over(partition by user_id order by sales desc) as rnk
from sales qualify rnk <=2

SELECT user_id, product_id, sales
FROM (
    SELECT user_id, product_id, sales,
           ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY sales DESC) AS rnk
    FROM sales
) AS ranked
WHERE rnk <= 2;

Q1.  Write a query to fetch each customer’s name, total number of claims, and total approved claim amount.
Input Tables:
Customer Table:
customer_id	name	age	gender
101	Rahul Sharma	35	M
102	Priya Verma	29	F
103	Amit Patel	42	M
104	Neha Singh	31	F
105	Sunil Mehra	48	M
106	Ritu Gupta	27	F

Claims Table:
claim_id	customer_id	claim_amount	claim_status
C001	101	10000	Approved
C002	102	25000	Rejected
C003	103	18000	Approved
C004	104	32000	Pending
C005	101	15000	Approved
C006	106	21000	Approved

Expected Output:
name	total_claims	approved_claim_amount
Rahul Sharma	2	25000
Priya Verma	1	0
Amit Patel	1	18000
Neha Singh	1	0
Sunil Mehra	0	0
Ritu Gupta	1	21000
		
with claims_agg_data as (
select customer_id, count(*) as total_claims,
sum(case 
	when claim_status = "Approved" then claim_amount
	else 0
	end) as approved_claim_amount
from claims group by customer_id
)
select 
name, 
coalesce(total_claims, 0),
coalesce(approved_claim_amount, 0)
from customer c
left join claims_agg_data cd
on cd.customer_id = c.customer_id

Q2. Customer Premium Behaviour Analysis
Input Tables:
Customer Table:
customer_id	name	age	gender
101	Rahul Sharma	35	M
102	Priya Verma	29	F
103	Amit Patel	42	M
104	Neha Singh	31	F
105	Sunil Mehra	48	M

Policy Table:
policy_id	customer_id	premium_amount	start_date	policy_type
201	101	10000	10-01-2023	Health
202	101	15000	15-06-2023	Health
203	102	12000	20-03-2023	Health
204	103	20000	05-02-2023	Critical Illness
205	104	18000	01-08-2023	Health
206	105	22000	18-07-2023	Health


Problem Statement – For each customer, find total premium paid, number of policies purchased, average premium paid, and most recent policy start date. Also, categorize the customers based on total premium paid:
•	‘High Value’ if total premium > 25000
•	‘Medium Value’ if between 15000 and 25000
•	‘Low Value’ otherwise
Expected Output:
customer_name	num_policies	total_premium	avg_premium	latest_policy_start_date	premium_category
Rahul Sharma	2	25000	12500	15-06-2023	Medium Value
Sunil Mehra	1	22000	22000	18-07-2023	Medium Value
Neha Singh	1	18000	18000	01-08-2023	Medium Value
Amit Patel	1	20000	20000	05-02-2023	Medium Value
Priya Verma	1	12000	12000	20-03-2023	Low Value

WITH policy_details AS (
    SELECT
        customer_id,
        COUNT(DISTINCT policy_id) AS num_policies,
        SUM(premium_amount) AS total_premium,
        AVG(premium_amount) AS avg_premium,
        MAX(start_date) AS latest_policy_start_date,
        CASE 
            WHEN SUM(premium_amount) > 25000 THEN 'High Value'
            WHEN SUM(premium_amount) BETWEEN 15000 AND 25000 THEN 'Medium Value'
            ELSE 'Low Value'
        END AS premium_category
    FROM policy 
    GROUP BY customer_id
)
SELECT 
    c.name AS customer_name,
    COALESCE(p.num_policies, 0) AS num_policies,
    COALESCE(p.total_premium, 0) AS total_premium,
    COALESCE(p.avg_premium, 0) AS avg_premium,
    COALESCE(p.latest_policy_start_date, '1999-01-01') AS latest_policy_start_date,
    COALESCE(p.premium_category, 'N/A') AS premium_category
FROM customer c
LEFT JOIN policy_details p
    ON c.customer_id = p.customer_id
ORDER BY c.customer_id;

Q1. Write a PySpark script that:
•	Reads both files from S3.
•	Joins customer and policy data.
•	Filters only Active policies.
•	Calculates total premium amount paid by each customer.
•	Returns the result as a DataFrame.
Files:
s3://insurance-data/customers.csv
s3://insurance-data/policies.csv
Schemas:
customers.csv:
customer_id,name,city
C001,Rahul,Delhi
C002,Anita,Mumbai
C003,Ajay,Bangalore
policies.csv:
policy_id,customer_id,premium_amount,status
P1001,C001,1200,Active
P1002,C002,800,Inactive
P1003,C001,500,Active
P1004,C003,900,Active
# File paths
c_path = "s3://insurance-data/customers.csv"
p_path = "s3://insurance-data/policies.csv"

# Read CSVs
c_df = spark.read.format("csv").option("header", True).load(c_path)
p_df = spark.read.format("csv").option("header", True).load(p_path)

# Join, filter only Active policies
join_df = (
    c_df.join(p_df, c_df.customer_id == p_df.customer_id, "inner")
        .filter(p_df.status == "Active")
        .select(c_df.customer_id, c_df.name, p_df.premium_amount)
)

# Aggregate total premium per customer
final_df = join_df.groupBy("customer_id", "name").agg(
    _sum("premium_amount").alias("total_amount")
)

# Show result
final_df.show(truncate=False)


Q2. Write a PySpark script that:
•	Ranks transactions of each customer by amount (highest first).
•	Returns top 2 transactions per customer.
File: 
s3://insurance-data/customer_transactions.csv
Schema of file:
customer_id,transaction_id,amount,transaction_date
C001,T1001,500,2024-01-01
C001,T1002,1200,2024-01-15
C002,T1003,800,2024-02-01
C001,T1004,400,2024-03-10
C002,T1005,1000,2024-03-15

# Read transactions file
df = spark.read.format("csv").option("header", True).load("s3://insurance-data/customer_transactions.csv")

# Convert amount to numeric (if needed, since CSV loads as string)
df = df.withColumn("amount", col("amount").cast("int"))

# Define window spec
window_spec = Window.partitionBy("customer_id").orderBy(col("amount").desc())

# Add rank column
df = df.withColumn("rank", row_number().over(window_spec))

# Filter top 2 per customer
df = df.filter(col("rank").isin([1, 2]))

df.show(truncate=False)

Q3. Write a PySpark script that detect Gaps in Customer Transactions
File:
s3://lumiq-data/insurance/customer_transactions.csv
Schema:
customer_id	transaction_date
C001	2023-01-10
C001	2023-02-12
C001	2023-04-15
C002	2023-01-05
C002	2023-03-07
Task:
•	Find missing months in customer payments.
•	Flag if the gap between transactions is more than 30 days.
Output Format:
customer_id	transaction_date	prev_date	days_diff	missing_month_flag
C001	2023-01-10	null	null	false
C001	2023-02-12	2023-01-10	33	true
C001	2023-04-15	2023-02-12	63	true
C002	2023-01-05	null	null	false
C002	2023-03-07	2023-01-05	61	true

# Read CSV
df = spark.read.format("csv").option("header", True).load("s3://lumiq-data/insurance/customer_transactions.csv")

# Convert to date
df = df.withColumn("transaction_date", to_date(col("transaction_date")))

# Define window
window_spec = Window.partitionBy("customer_id").orderBy(col("transaction_date"))

# Previous transaction date
df = df.withColumn("prev_date", lag("transaction_date").over(window_spec))

# Days difference
df = df.withColumn("days_diff", datediff(col("transaction_date"), col("prev_date")))

# Missing month flag (gap > 30 days)
df = df.withColumn("missing_month_flag", when(col("days_diff") > 30, True).otherwise(False))

df.show(truncate=False)

Q1. You are given a list of customer transactions in JSON format. Each record contains customer_id, transaction_id, and amount. Return the total transaction amount per customer.
Sample Input:
transactions = [
    {"customer_id": "C001", "transaction_id": "T1001", "amount": 1200},
    {"customer_id": "C002", "transaction_id": "T1002", "amount": 850},
    {"customer_id": "C001", "transaction_id": "T1003", "amount": 500},
    {"customer_id": "C003", "transaction_id": "T1004", "amount": 700},
    {"customer_id": "C002", "transaction_id": "T1005", "amount": 150}
]
Expected Output:
{
    "C001": 1700,
    "C002": 1000,
    "C003": 700
}

final_ans = {}
for row in transactions:
    c_id = row['customer_id']
    amt = row['amount']
    final_ans[c_id] = final_ans.get(c_id, 0) + amt

print(final_ans)

Question:
You are given the following tables:

customers (customer_id, customer_name, …)

rides (trip_id, customer_id, payment_id, …)

payments (payment_id, payment_type, …)

ratings (trip_id, rating, …)

A customer is considered for loyalty calculation only if they paid using card or ryd_credit.

Define a loyalty score as:

10 points for each valid ride (paid using card or ryd_credit).

5 points for each valid rating (i.e., if the customer rated such a ride).

Write a SQL query to return the top 100 customers (by loyalty score), showing:

customer_id

customer_name

loyalty_score

Order the result by loyalty_score (descending) and then by customer_id (ascending).











